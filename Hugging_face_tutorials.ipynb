{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9991129040718079},\n",
       " {'label': 'POSITIVE', 'score': 0.997535228729248}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifer = pipeline(\"sentiment-analysis\")\n",
    "classifer([\"I hate you\",\n",
    "           \"Hello everyone, today my wife passed away but I have duties of serving the country so here I am\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--facebook--bart-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': \"You should have an understanding of keras, tensorflow and other deep learning libraries to get the model runnuing for the company's profit\",\n",
       " 'labels': ['ai engineer',\n",
       "  'Business analyst',\n",
       "  'data engineer',\n",
       "  'data scientist',\n",
       "  'data analyst',\n",
       "  'NLP engineer'],\n",
       " 'scores': [0.2206030935049057,\n",
       "  0.20578259229660034,\n",
       "  0.18932028114795685,\n",
       "  0.1728699505329132,\n",
       "  0.11665910482406616,\n",
       "  0.09476497024297714]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer = pipeline(\"zero-shot-classification\")\n",
    "classifer(\"You should have an understanding of keras, tensorflow and other deep learning libraries to get the model runnuing for the company's profit\",\n",
    "candidate_labels=[\"Business analyst\", \"data analyst\", \"data scientist\", \"data engineer\", \"NLP engineer\", \"ai engineer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': \"You should have an understanding of keras, tensorflow and other hugging face libraries related to language processing to get the model runnuing for the company's profit\",\n",
       " 'labels': ['NLP engineer',\n",
       "  'ai engineer',\n",
       "  'Business analyst',\n",
       "  'data scientist',\n",
       "  'data engineer',\n",
       "  'data analyst'],\n",
       " 'scores': [0.2349623441696167,\n",
       "  0.22076167166233063,\n",
       "  0.17149867117404938,\n",
       "  0.15001338720321655,\n",
       "  0.13137005269527435,\n",
       "  0.09139384329319]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer = pipeline(\"zero-shot-classification\")\n",
    "classifer(\"You should have an understanding of keras, tensorflow and other hugging face libraries related to language processing to get the model runnuing for the company's profit\",\n",
    "candidate_labels=[\"Business analyst\", \"data analyst\", \"data scientist\", \"data engineer\", \"NLP engineer\", \"ai engineer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Business analysis using Tableau and the University of Wisconsin – Madison.\\n\\nTable 6: Public Sector Employment in 2014\\n\\n\\n1. Top 20% of Gilded Age Workforce. 2. Top 3% of Gilded Age Workforce.\\n'},\n",
       " {'generated_text': 'Business analysis using Tableau and Google Sheets to assess the economic effects of the proposed tax increase on businesses across all industries\\n\\n*Data for the tax increases in 2014–15 were released in Tableau and Google Sheets, and are not used'},\n",
       " {'generated_text': 'Business analysis using Tableau\\n\\nThese estimates show that many American employers are paying employees below the poverty level, and those workers have the resources to make ends meet as they have for many years.\\n\\nThe findings can be used by people who want'},\n",
       " {'generated_text': 'Business analysis using Tableau is included for your personal reference.\\n\\nDownload the tableau file for this data HERE'},\n",
       " {'generated_text': 'Business analysis using Tableau, data available on the OpenStreetMap wiki\\n\\nUsing the map on Tableau\\n\\nYou can use Tableau to create a map with a geographic center. To add a map to Tableau, click Map in the'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"gpt2-medium\")\n",
    "generator(\"Business analysis using Tableau\", max_length=50, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List 5 detailed bullet points to include on a resume for a project titled 'Business analysis using Tableau'. The points should highlight key skills, tools used, and significant achievements. 1. Career track track 2. Career track summary 3. Tableau skills, skills, and performance 4. Tableau career track summary to include on resume 2\n",
      "\n",
      "What Is Tableau? Tableau allows you to have real time interaction between your data, reports, and documents. When people look at the table, they see a series of documents that are related to a process. The more relevant the document, the more they are able to see the processes of a company. Tableau provides real time visibility into the process of a business or company. 1. Learn more about tableau 2. Read Tableau: An Introduction to the Big Data and Visualization Marketplace 3. Read Tableau 3.1: Tableau Resources: Big Data in Business 4. Tableau Resources: Data Sources 5. Tableau Resources:\n"
     ]
    }
   ],
   "source": [
    "# Provide more context in the prompt\n",
    "prompt = (\n",
    "    \"List 5 detailed bullet points to include on a resume for a project titled 'Business analysis using Tableau'. \"\n",
    "    \"The points should highlight key skills, tools used, and significant achievements. \"\n",
    "    \"1.\"\n",
    ")\n",
    "\n",
    "response = generator(prompt, max_length=200, num_return_sequences=1)\n",
    "\n",
    "generated_text = response[0]['generated_text']\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 1 for a 5 point description of a project using a job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. List 5 detailed bullet points to include on a resume for a project titled 'Fine Tuning LLM Model for psychometric data'. The points should highlight key skills, tools used, and significant achievements, using the following job description: About myUniMate: myUniMate is an early\n",
      "2. stage pioneering student engagement platform designed to redefine the college journey. We believe the student should be at the core of every experience. myUniMate is challenging the limits of generative AI and machine learning, for students to maximize the academic, social, and career aspects of their university adventure! We are seeking enthusiastic individuals who are motivated by ambitious goals to fulfill our mission. Ideal candidates thrive in a startup atmosphere, where challenging and unsolved problems are abundant. We value team members who are keen to learn, grow, and engage in collaborative efforts. Role Overview: We are seeking a highly experienced and visionary AI Architect to lead the development and implementation of cutting\n",
      "3. edge AI solutions. The ideal candidate will have extensive experience in AI/ML technologies, particularly in designing and deploying scalable and efficient AI systems in a dynamic startup environment. Key Responsibilities: Support the design and execution of AI architecture strategies, ensuring alignment with business goals and technological advancements. Collaborate with cross\n",
      "4. functional teams, including Data Science and Engineering, to create innovative AI solutions. Evaluate and recommend AI/ML platforms and technologies for implementation, and provide governance and direction on architectural matters. Play a key role in the end\n",
      "5. to\n",
      "6. end solution of AI projects, from conception to deployment. Contribute to the AI team, fostering a culture of continuous learning and innovation. Engage with stakeholders across the organization to promote and implement the established AI architectural vision. Stay abreast of emerging trends and advancements in AI and ML, applying this knowledge to drive continuous improvement in our AI capabilities. Qualifications: Bachelor’s or Master’s degree in Computer Science, AI, or a related field; a Ph.D. is a plus. Demonstrated expertise in designing and deploying AI/ML solutions, particularly in a cloud environment (Azure, GCP, AWS). Strong knowledge of machine learning algorithms, NLP, predictive analytics, and generative AI technologies. Proficiency in programming languages such as Python, R, or Java, and familiarity with AI frameworks like TensorFlow, PyTorch, or Keras. Solid understanding of data architecture concepts, big data technologies, and MLOps practices. Excellent communication skills, with the ability to articulate complex technical concepts to both technical and non\n",
      "7. technical audiences. Proven leadership skills and experience in mentoring and guiding teams. Benefits: A role where your contributions significantly impact the company's growth. Opportunities for professional development in technology and content creation. Competitive benefits, company equity, and a generous work\n",
      "8. life balance. A collaborative, innovative, and inclusive work culture. Why You'll Love Working with Us: Work on cutting\n",
      "9. edge AI technologies that redefine the student experience. Collaborate with a passionate team dedicated to innovation and excellence. Contribute to a platform that has a significant impact on students' university journey. How to Apply: If you are a strategic thinker with a passion for AI and a track record of delivering successful AI solutions, we invite you to apply to become an integral part of our team at myUniMate. Each point should be concise and follow the order of the project's execution. 1. An Interview: Prepare and submit your CV, cover letter, and cover letter to myUniMate. We need a candidate to demonstrate a strong understanding of all aspects of machine learning, and their ability to apply the underlying principles to solve real\n",
      "10. world problems. Ideally you should have strong interpersonal skills, strong analytical skills, and a basic understanding of data science and data mining. This includes but is not limited to, the ability to code code and code code and explain complex techniques to non\n",
      "11. technical people without being difficult. An ideal candidate should be articulate and approachable. 2. Project Planning: Prepare the draft project proposal to communicate your role, priorities, and goals for the project. If you are a junior, senior, or member of a\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# Load the text generation pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2-medium\")\n",
    "\n",
    "# Example job description (replace this with the actual job description)\n",
    "job_description = (\n",
    "    \"About myUniMate: myUniMate is an early-stage pioneering student engagement platform designed to redefine the college journey. \"\n",
    "    \"We believe the student should be at the core of every experience. myUniMate is challenging the limits of generative AI and machine learning, \"\n",
    "    \"for students to maximize the academic, social, and career aspects of their university adventure! \"\n",
    "    \"We are seeking enthusiastic individuals who are motivated by ambitious goals to fulfill our mission. Ideal candidates thrive in a startup atmosphere, \"\n",
    "    \"where challenging and unsolved problems are abundant. We value team members who are keen to learn, grow, and engage in collaborative efforts. \"\n",
    "    \"Role Overview: We are seeking a highly experienced and visionary AI Architect to lead the development and implementation of cutting-edge AI solutions. \"\n",
    "    \"The ideal candidate will have extensive experience in AI/ML technologies, particularly in designing and deploying scalable and efficient AI systems in a dynamic startup environment. \"\n",
    "    \"Key Responsibilities: Support the design and execution of AI architecture strategies, ensuring alignment with business goals and technological advancements. \"\n",
    "    \"Collaborate with cross-functional teams, including Data Science and Engineering, to create innovative AI solutions. \"\n",
    "    \"Evaluate and recommend AI/ML platforms and technologies for implementation, and provide governance and direction on architectural matters. \"\n",
    "    \"Play a key role in the end-to-end solution of AI projects, from conception to deployment. \"\n",
    "    \"Contribute to the AI team, fostering a culture of continuous learning and innovation. \"\n",
    "    \"Engage with stakeholders across the organization to promote and implement the established AI architectural vision. \"\n",
    "    \"Stay abreast of emerging trends and advancements in AI and ML, applying this knowledge to drive continuous improvement in our AI capabilities. \"\n",
    "    \"Qualifications: Bachelor’s or Master’s degree in Computer Science, AI, or a related field; a Ph.D. is a plus. \"\n",
    "    \"Demonstrated expertise in designing and deploying AI/ML solutions, particularly in a cloud environment (Azure, GCP, AWS). \"\n",
    "    \"Strong knowledge of machine learning algorithms, NLP, predictive analytics, and generative AI technologies. \"\n",
    "    \"Proficiency in programming languages such as Python, R, or Java, and familiarity with AI frameworks like TensorFlow, PyTorch, or Keras. \"\n",
    "    \"Solid understanding of data architecture concepts, big data technologies, and MLOps practices. \"\n",
    "    \"Excellent communication skills, with the ability to articulate complex technical concepts to both technical and non-technical audiences. \"\n",
    "    \"Proven leadership skills and experience in mentoring and guiding teams. \"\n",
    "    \"Benefits: A role where your contributions significantly impact the company's growth. \"\n",
    "    \"Opportunities for professional development in technology and content creation. \"\n",
    "    \"Competitive benefits, company equity, and a generous work-life balance. \"\n",
    "    \"A collaborative, innovative, and inclusive work culture. \"\n",
    "    \"Why You'll Love Working with Us: Work on cutting-edge AI technologies that redefine the student experience. \"\n",
    "    \"Collaborate with a passionate team dedicated to innovation and excellence. \"\n",
    "    \"Contribute to a platform that has a significant impact on students' university journey. \"\n",
    "    \"How to Apply: If you are a strategic thinker with a passion for AI and a track record of delivering successful AI solutions, we invite you to apply to become an integral part of our team at myUniMate.\"\n",
    ")\n",
    "\n",
    "# Construct the prompt\n",
    "prompt = (\n",
    "    \"List 5 detailed bullet points to include on a resume for a project titled 'Fine Tuning LLM Model for psychometric data'. \"\n",
    "    \"The points should highlight key skills, tools used, and significant achievements, using the following job description: \"\n",
    "    f\"{job_description} \"\n",
    "    \"Each point should be concise and follow the order of the project's execution. \"\n",
    "    \"1.\"\n",
    ")\n",
    "\n",
    "# Generate the text with a specified number of new tokens\n",
    "response = generator(prompt, max_new_tokens=150, num_return_sequences=1)\n",
    "\n",
    "# Extract the generated text\n",
    "generated_text = response[0]['generated_text']\n",
    "\n",
    "# Split the text into bullet points based on common delimiters\n",
    "bullet_points = re.split(r'[\\n•*-]', generated_text)\n",
    "\n",
    "# Clean up and print each bullet point\n",
    "for i, point in enumerate(bullet_points, start=1):\n",
    "    point = point.strip()\n",
    "    if point and point != \"1.\":\n",
    "        print(f\"{i}. {point}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. List 5 detailed bullet points to include on a resume for a project titled 'Fine Tuning LLM Model for psychometric data'. The points should highlight key skills, tools used, and significant achievements, using the following job description: Support the design and execution of AI architecture strategies, ensuring alignment with business goals and technological advancements.Collaborate with cross\n",
      "2. functional teams, including Data Science and Engineering, to create innovative AI solutions.Evaluate and recommend AI/ML platforms and technologies for implementation, and provide governance and direction on architectural matters.Play a key role in the end\n",
      "3. to\n",
      "4. end solution of AI projects, from conception to deployment.Contribute to the AI team, fostering a culture of continuous learning and innovation.Engage with stakeholders across the organization to promote and implement the established AI architectural vision.Stay abreast of emerging trends and advancements in AI and ML, applying this knowledge to drive continuous improvement in our AI capabilities. Each point should be concise and follow the order of the project's execution. 1. An Introduction 3. A Practical Example 4. A Productive Solution 5. A Case Study 6. Conclusion 7. Key Points Key points 5\n",
      "6. Projects should be set up so that the project requires no knowledge of ML; for example, no knowledge of ML is required to start or complete a cross\n",
      "7. functional group project, no knowledge of ML is required to support an end\n",
      "8. to\n",
      "9. end business case, and no knowledge of ML is required to provide governance or direction to the project team. ML projects should also not require any prior knowledge of design languages.\n",
      "11. It should not be necessary to meet a number of deadlines to deliver a ML project; you must plan in advance to implement and evaluate a single ML project.\n",
      "13. Each\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# Load the text generation pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2-medium\")\n",
    "\n",
    "# Example job description (replace this with the actual job description)\n",
    "job_description = (\n",
    "    \"Support the design and execution of AI architecture strategies, ensuring alignment with business goals and technological advancements.\"\n",
    "\"Collaborate with cross-functional teams, including Data Science and Engineering, to create innovative AI solutions.\"\n",
    "\n",
    "\"Evaluate and recommend AI/ML platforms and technologies for implementation, and provide governance and direction on architectural matters.\"\n",
    "\n",
    "\"Play a key role in the end-to-end solution of AI projects, from conception to deployment.\"\n",
    "\n",
    "\"Contribute to the AI team, fostering a culture of continuous learning and innovation.\"\n",
    "\n",
    "\"Engage with stakeholders across the organization to promote and implement the established AI architectural vision.\"\n",
    "\n",
    "\"Stay abreast of emerging trends and advancements in AI and ML, applying this knowledge to drive continuous improvement in our AI capabilities.\" )\n",
    "\n",
    "# Construct the prompt\n",
    "prompt = (\n",
    "    \"List 5 detailed bullet points to include on a resume for a project titled 'Fine Tuning LLM Model for psychometric data'. \"\n",
    "    \"The points should highlight key skills, tools used, and significant achievements, using the following job description: \"\n",
    "    f\"{job_description} \"\n",
    "    \"Each point should be concise and follow the order of the project's execution. \"\n",
    "    \"1.\"\n",
    ")\n",
    "\n",
    "# Generate the text with a specified number of new tokens\n",
    "response = generator(prompt, max_new_tokens=150, num_return_sequences=1)\n",
    "\n",
    "# Extract the generated text\n",
    "generated_text = response[0]['generated_text']\n",
    "\n",
    "# Split the text into bullet points based on common delimiters\n",
    "bullet_points = re.split(r'[\\n•*-]', generated_text)\n",
    "\n",
    "# Clean up and print each bullet point\n",
    "for i, point in enumerate(bullet_points, start=1):\n",
    "    point = point.strip()\n",
    "    if point and point != \"1.\":\n",
    "        print(f\"{i}. {point}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2810764014720917,\n",
       "  'token': 2734,\n",
       "  'token_str': ' fashion',\n",
       "  'sequence': 'This course will teach you all about fashion models from Victoria Secret University.'},\n",
       " {'score': 0.17385698854923248,\n",
       "  'token': 10996,\n",
       "  'token_str': ' runway',\n",
       "  'sequence': 'This course will teach you all about runway models from Victoria Secret University.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models from Victoria Secret University.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
